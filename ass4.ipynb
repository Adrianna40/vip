{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import List, T\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'caltech-101/101_ObjectCategories'\n",
    "test_size = 0.2\n",
    "k = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for dir in dirs:\n",
    "        \n",
    "        for cat_root, cat_dirs, cat_files in os.walk(os.path.join(dataset_path, dir)):\n",
    "            \n",
    "            if len(cat_files) >= 100:\n",
    "                categories.append(dir)\n",
    "                print(dir, len(cat_files))\n",
    "              \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(dataset_path : str, category : str, test_size : float) -> List[str]:\n",
    "    \"\"\" \n",
    "    returns names of files for test and train datasets of particular category\n",
    "    \"\"\"\n",
    "    files_paths = []\n",
    "    for root, dirs, files in os.walk(os.path.join(dataset_path, category)):\n",
    "        for name in files:\n",
    "            files_paths.append(os.path.join(root, name))\n",
    "    train_files, test_files = train_test_split(files_paths, test_size=test_size)\n",
    "    return train_files, test_files\n",
    "\n",
    "def load_images(files_paths : List[str]) -> List[np.ndarray]:\n",
    "    images = []\n",
    "    for file in files_paths:\n",
    "        img = cv2.imread(file,0)\n",
    "        images.append(img)\n",
    "    return images\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test datasets \n",
    "train_images = {}\n",
    "test_images = {}\n",
    "for cat in categories:\n",
    "    train_files, test_files = get_file_paths(dataset_path, cat, test_size)\n",
    "    train_images[cat] = load_images(train_files)\n",
    "    test_images[cat] = load_images(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_features(images):\n",
    "    descriptor_dict = {}\n",
    "    descriptor_list = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for category, cat_images in images.items():\n",
    "        features = []\n",
    "        for img in cat_images:\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "            if (des is not None):\n",
    "                descriptor_list.extend(des)\n",
    "                features.append(des)\n",
    "            else: \n",
    "                print(f'image number {cat_images.index(img)} has no descriptors')\n",
    "        descriptor_dict[category] = features\n",
    "    return [descriptor_list, descriptor_dict]\n",
    "\n",
    "print('train')\n",
    "descriptor_list, all_bovw_feature = sift_features(train_images) \n",
    "print('test')\n",
    "_, test_bovw_feature = sift_features(test_images)\n",
    "# descriptor_list is needed for creating clustering centers, so we only take them from train dataset\n",
    "# bovw_feature for train and test are needed for classification of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array that holds central points (visual words)\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_ \n",
    "    return visual_words\n",
    "  \n",
    "visual_words = kmeans(k, descriptor_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(feature : np.ndarray, centers : np.ndarray):\n",
    "    # returns an index of the visual word that is the most similar to a feature \n",
    "    minimum = 0\n",
    "    start_min = True \n",
    "    min_index = 0 \n",
    "    for idx, center in enumerate(centers): \n",
    "        distance_c = distance.cosine(center, feature)\n",
    "        if start_min:\n",
    "            minimum = distance_c\n",
    "            start_min = False \n",
    "        else: \n",
    "            minimum = min(minimum, distance_c)\n",
    "            if minimum == distance_c:\n",
    "                min_index = idx\n",
    "\n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 2 parameters: \n",
    "# - a dictionary that holds the descriptors that are separated class by class \n",
    "# - an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "def image_class(all_bovw, centers):\n",
    "    bovw = {}\n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for feature in img:\n",
    "                ind = find_index(feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        bovw[key] = category\n",
    "    return bovw\n",
    "    \n",
    "# Creates histograms for train data    \n",
    "bovw_train = image_class(all_bovw_feature, visual_words) \n",
    "# Creates histograms for test data\n",
    "bovw_test = image_class(test_bovw_feature, visual_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_json(file_name, bovw):\n",
    "    bovw_list = {cat : list(bovw[cat][0]) for cat in bovw.keys()}\n",
    "    json_object = json.dumps(bovw_list)\n",
    "    with open(file_name, 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "save_to_json('bovw_test.json', bovw_test)\n",
    "save_to_json('bovw_train.json', bovw_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words_counter(hist1, hist2):\n",
    "    cnt = 0\n",
    "    for idx, word in enumerate(hist1):\n",
    "        cnt += min(hist1[idx], hist2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-NN algorithm. We use this for predict the class of test images.\n",
    "# Takes 2 parameters\n",
    "# - images : feature vectors of train images \n",
    "# - tests : feature vectors of test images\n",
    "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "    \n",
    "    for test_category, test_histograms_list in tests.items():\n",
    "        class_based[test_category] = [0, 0] # [correct, all]\n",
    "        for test_histogram in test_histograms_list:\n",
    "            min_start = True \n",
    "            for train_category, train_histograms_list in images.items():\n",
    "                for train_histogram in train_histograms_list:\n",
    "                    if min_start:\n",
    "                        minimum = distance.euclidean(test_histogram, train_histogram)\n",
    "                        pred = train_category\n",
    "                        min_start = False\n",
    "                    else:\n",
    "                        dist = distance.euclidean(test_histogram, train_histogram)\n",
    "                        if(dist < minimum):\n",
    "                            minimum = dist\n",
    "                            pred = train_category\n",
    "            \n",
    "            if(test_category == pred):\n",
    "                correct_predict += 1\n",
    "                class_based[test_category][0] += 1\n",
    "            num_test += 1\n",
    "            class_based[test_category][1] += 1\n",
    "\n",
    "    return [num_test, correct_predict, class_based]\n",
    "    \n",
    "# Call the knn function    \n",
    "results_bowl = knn(bovw_train, bovw_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average accuracy and class based accuracies.  \n",
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"\\nClass based accuracies: \\n\")\n",
    "    for key,value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(key + \" : %\" + str(acc))\n",
    "        \n",
    "# Calculates the accuracies and write the results to the console.       \n",
    "accuracy(results_bowl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, axes = plt.subplots(6, 2)\n",
    "fig.set_size_inches(20, 20)\n",
    "for ax, cat in zip(axes, categories):\n",
    "    ax[0].hist(bovw_train[cat], bins=k)\n",
    "    ax[0].set_title(f'{cat} train histogram')\n",
    "    ax[1].hist(bovw_test[cat], bins=k)\n",
    "    ax[1].set_title(f'{cat} test histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('VipEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f80cf855238dad53e7f71a0dc444bfb449a810ab69bda85ea45592e78e21e7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
